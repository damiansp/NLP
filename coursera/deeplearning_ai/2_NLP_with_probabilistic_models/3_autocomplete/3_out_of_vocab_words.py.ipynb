{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the new vocabulary containing 3 most frequent words: ['happy', 'because', 'learning']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "M = 3\n",
    "word_counts = {\n",
    "    'happy': 5, 'because': 3, 'i': 2, 'am': 2, 'learning': 3, '.': 1}\n",
    "vocabulary = Counter(word_counts).most_common(M)\n",
    "vocabulary = [w[0] for w in vocabulary]\n",
    "\n",
    "print(f'the new vocabulary containing {M} most frequent words: '\n",
    "      f'{vocabulary}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence: ['am', 'i', 'learning']\n",
      "output sentence: ['<UNK>', '<UNK>', 'learning']\n"
     ]
    }
   ],
   "source": [
    "sentence = ['am', 'i', 'learning']\n",
    "output_sentence = []\n",
    "print(f'input sentence: {sentence}')\n",
    "\n",
    "for w in sentence:\n",
    "    if w in vocabulary:\n",
    "        output_sentence.append(w)\n",
    "    else:\n",
    "        output_sentence.append('<UNK>')        \n",
    "print(f'output sentence: {output_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because\n",
      "learning\n"
     ]
    }
   ],
   "source": [
    "f = 3\n",
    "for word, freq in word_counts.items():\n",
    "    if freq == f:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity for the training set: 1.2599210498948732\n",
      "perplexity for the training set with <UNK>: 1.0\n"
     ]
    }
   ],
   "source": [
    "training_set = ['i', 'am', 'happy', 'because','i', 'am', 'learning', '.']\n",
    "training_set_unk = [\n",
    "    'i', 'am', '<UNK>', '<UNK>','i', 'am', '<UNK>', '<UNK>']\n",
    "test_set = ['i', 'am', 'learning']\n",
    "test_set_unk = ['i', 'am', '<UNK>']\n",
    "M = len(test_set)\n",
    "probability = 1\n",
    "probability_unk = 1\n",
    "\n",
    "bigram_probabilities = {('i', 'am'): 1.0, \n",
    "                        ('am', 'happy'): 0.5, \n",
    "                        ('happy', 'because'): 1.0, \n",
    "                        ('because', 'i'): 1.0, \n",
    "                        ('am', 'learning'): 0.5, \n",
    "                        ('learning', '.'): 1.0}\n",
    "bigram_probabilities_unk = {('i', 'am'): 1.0, \n",
    "                            ('am', '<UNK>'): 1.0, \n",
    "                            ('<UNK>', '<UNK>'): 0.5, \n",
    "                            ('<UNK>', 'i'): 0.25}\n",
    "\n",
    "for i in range(len(test_set) - 2 + 1):\n",
    "    bigram = tuple(test_set[i: i + 2])\n",
    "    probability = probability * bigram_probabilities[bigram]        \n",
    "    bigram_unk = tuple(test_set_unk[i: i + 2])\n",
    "    probability_unk = (probability_unk \n",
    "                       * bigram_probabilities_unk[bigram_unk])\n",
    "perplexity = probability ** (-1 / M)\n",
    "perplexity_unk = probability_unk ** (-1 / M)\n",
    "print(f'perplexity for the training set: {perplexity}')\n",
    "print(f'perplexity for the training set with <UNK>: {perplexity_unk}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_k_smoothing_probability(\n",
    "        k, vocabulary_size, n_gram_count, n_gram_prefix_count):\n",
    "    numerator = n_gram_count + k\n",
    "    denominator = n_gram_prefix_count + k*vocabulary_size\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability_known_trigram: 0.2\n",
      "probability_unknown_trigram: 0.2\n"
     ]
    }
   ],
   "source": [
    "trigram_probabilities = {('i', 'am', 'happy') : 2}\n",
    "bigram_probabilities = {( 'am', 'happy') : 10}\n",
    "vocabulary_size = 5\n",
    "k = 1\n",
    "probability_known_trigram = add_k_smoothing_probability(\n",
    "    k, \n",
    "    vocabulary_size, \n",
    "    trigram_probabilities[('i', 'am', 'happy')], \n",
    "    bigram_probabilities[( 'am', 'happy')])\n",
    "probability_unknown_trigram = add_k_smoothing_probability(\n",
    "    k, \n",
    "    vocabulary_size, \n",
    "    0, \n",
    "    0)\n",
    "print(f'probability_known_trigram: {probability_known_trigram}')\n",
    "print(f'probability_unknown_trigram: {probability_unknown_trigram}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "besides the trigram ('are', 'you', 'happy') we also use bigram ('you', 'happy') and unigram (happy)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_probabilities = {('i', 'am', 'happy'): 0}\n",
    "bigram_probabilities = {( 'am', 'happy'): 0.3}\n",
    "unigram_probabilities = {'happy': 0.4}\n",
    "trigram = ('are', 'you', 'happy')\n",
    "bigram = trigram[1: 3]\n",
    "unigram = trigram[2]\n",
    "print(f'besides the trigram {trigram} we also use bigram {bigram} and '\n",
    "      f'unigram ({unigram})\\n')\n",
    "lambda_factor = 0.4\n",
    "probability_hat_trigram = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for trigram ('are', 'you', 'happy') not found\n",
      "probability for bigram ('you', 'happy') not found\n",
      "probability for unigram happy found\n",
      "\n",
      "probability for trigram ('are', 'you', 'happy') estimated as 0.06400000000000002\n"
     ]
    }
   ],
   "source": [
    "if (trigram not in trigram_probabilities \n",
    "        or trigram_probabilities[trigram] == 0):\n",
    "    print(f'probability for trigram {trigram} not found')\n",
    "    if (bigram not in bigram_probabilities \n",
    "            or bigram_probabilities[bigram] == 0):\n",
    "        print(f'probability for bigram {bigram} not found')\n",
    "        if unigram in unigram_probabilities:\n",
    "            print(f'probability for unigram {unigram} found\\n')\n",
    "            probability_hat_trigram = (lambda_factor \n",
    "                                       * lambda_factor \n",
    "                                       * unigram_probabilities[unigram])\n",
    "        else:\n",
    "            probability_hat_trigram = 0\n",
    "    else:\n",
    "        probability_hat_trigram = (lambda_factor \n",
    "                                   * bigram_probabilities[bigram])\n",
    "else:\n",
    "    probability_hat_trigram = trigram_probabilities[trigram]\n",
    "print(f'probability for trigram {trigram} estimated as '\n",
    "      f'{probability_hat_trigram}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "besides the trigram ('i', 'am', 'happy') we also use bigram ('am', 'happy') andunigram (happy)\n",
      "\n",
      "estimated probability of the input trigram ('i', 'am', 'happy') is 0.12\n"
     ]
    }
   ],
   "source": [
    "trigram_probabilities = {('i', 'am', 'happy'): 0.15}\n",
    "bigram_probabilities = {( 'am', 'happy'): 0.3}\n",
    "unigram_probabilities = {'happy': 0.4}\n",
    "lambda_1 = 0.8\n",
    "lambda_2 = 0.15\n",
    "lambda_3 = 0.05\n",
    "\n",
    "trigram = ('i', 'am', 'happy')\n",
    "bigram = trigram[1: 3]\n",
    "unigram = trigram[2]\n",
    "print(f'besides the trigram {trigram} we also use bigram {bigram} and'\n",
    "      f'unigram ({unigram})\\n')\n",
    "\n",
    "probability_hat_trigram = (lambda_1 * trigram_probabilities[trigram] \n",
    "                           + lambda_2 * bigram_probabilities[bigram]\n",
    "                           + lambda_3 * unigram_probabilities[unigram])\n",
    "print(f'estimated probability of the input trigram {trigram} is '\n",
    "      f'{probability_hat_trigram}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
