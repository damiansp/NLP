{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from   trax import layers as tl\n",
    "from   trax import fastmath, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trax                     1.3.5\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 list | grep trax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Relu\n",
      "expected inputs: 1\n",
      "promised outputs: 1\n"
     ]
    }
   ],
   "source": [
    "# Layers\n",
    "# Create a trax layer:\n",
    "relu = tl.Relu()\n",
    "\n",
    "print('name:', relu.name)\n",
    "print('expected inputs:', relu.n_in)\n",
    "print('promised outputs:', relu.n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [-2 -1  0  1  2]\n",
      "Outputs: [0 0 0 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "print('Inputs:', x)\n",
    "\n",
    "# out\n",
    "y = relu(x)\n",
    "print('Outputs:', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Concatenate', 2, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat = tl.Concatenate()\n",
    "concat.name, concat.n_in, concat.n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10 -20 -30]\n",
      "[1. 2. 3.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([-10., -20., -30.,   1.,   2.,   3.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([-10, -20, -30])\n",
    "x2 = x1 / -10\n",
    "print(x1)\n",
    "print(x2)\n",
    "\n",
    "y = concat([x1, x2])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Concatenate', 3, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_3 = tl.Concatenate(n_items=3)\n",
    "concat_3.name, concat_3.n_in, concat_3.n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-10.  , -20.  , -30.  ,   1.  ,   2.  ,   3.  ,   0.99,\n",
       "               1.98,   2.97], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = x2 * 0.99\n",
    "y = concat_3([x1, x2, x3])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) <class 'tuple'>\n",
      "ShapeDtype{shape:(4,), dtype:float64} <class 'trax.shapes.ShapeDtype'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jax/lax/lax.py:6188: UserWarning: Explicitly requested dtype float64 requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  warnings.warn(msg.format(dtype, fun_name , truncated_dtype))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jax/lax/lax.py:6188: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  warnings.warn(msg.format(dtype, fun_name , truncated_dtype))\n"
     ]
    }
   ],
   "source": [
    "norm = tl.LayerNorm()\n",
    "x = np.array([0, 1, 2, 3], dtype='float')\n",
    "norm.init(shapes.signature(x))\n",
    "\n",
    "print(x.shape, type(x.shape))\n",
    "print(shapes.signature(x), type(shapes.signature(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LayerNorm', 1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.name, norm.n_in, norm.n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([1., 1., 1., 1.], dtype=float32),\n",
       " DeviceArray([0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(norm.weights[0], # W\n",
    " norm.weights[1]) # b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-1.3416404 , -0.44721344,  0.44721344,  1.3416404 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = norm(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Fn in module trax.layers.base:\n",
      "\n",
      "Fn(name, f, n_out=1)\n",
      "    Returns a layer with no weights that applies the function `f`.\n",
      "    \n",
      "    `f` can take and return any number of arguments, and takes only positional\n",
      "    arguments -- no default or keyword arguments. It often uses JAX-numpy (`jnp`).\n",
      "    The following, for example, would create a layer that takes two inputs and\n",
      "    returns two outputs -- element-wise sums and maxima:\n",
      "    \n",
      "        `Fn('SumAndMax', lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)), n_out=2)`\n",
      "    \n",
      "    The layer's number of inputs (`n_in`) is automatically set to number of\n",
      "    positional arguments in `f`, but you must explicitly set the number of\n",
      "    outputs (`n_out`) whenever it's not the default value 1.\n",
      "    \n",
      "    Args:\n",
      "      name: Class-like name for the resulting layer; for use in debugging.\n",
      "      f: Pure function from input tensors to output tensors, where each input\n",
      "          tensor is a separate positional arg, e.g., `f(x0, x1) --> x0 + x1`.\n",
      "          Output tensors must be packaged as specified in the `Layer` class\n",
      "          docstring.\n",
      "      n_out: Number of outputs promised by the layer; default value 1.\n",
      "    \n",
      "    Returns:\n",
      "      Layer executing the function `f`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tl.Fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def a custom layer (looks like an ideal candidate for decorator)\n",
    "def times_two():\n",
    "    layer_name = 'times_two'\n",
    "\n",
    "    def f(x):\n",
    "        return 2*x\n",
    "    \n",
    "    return tl.Fn(layer_name, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times_two\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "ttwo = times_two()\n",
    "\n",
    "print(ttwo.name)\n",
    "print(ttwo.n_in)\n",
    "print(ttwo.n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = ttwo(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial combinator\n",
    "serial = tl.Serial(tl.LayerNorm(), \n",
    "                   tl.Relu(), \n",
    "                   ttwo, \n",
    "                   tl.Dense(n_units=2), \n",
    "                   tl.Dense(n_units=1), \n",
    "                   tl.LogSoftmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jax/lax/lax.py:6188: UserWarning: Explicitly requested dtype int64 requested in ones is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  warnings.warn(msg.format(dtype, fun_name , truncated_dtype))\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jax/lax/lax.py:6188: UserWarning: Explicitly requested dtype int64 requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  warnings.warn(msg.format(dtype, fun_name , truncated_dtype))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Serial[\n",
       "  LayerNorm\n",
       "  Relu\n",
       "  times_two\n",
       "  Dense_2\n",
       "  Dense_1\n",
       "  LogSoftmax\n",
       "]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "serial.init(shapes.signature(x))\n",
    "serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial\n",
      "[LayerNorm, Relu, times_two, Dense_2, Dense_1, LogSoftmax]\n",
      "1\n",
      "1\n",
      "((DeviceArray([1, 1, 1, 1, 1], dtype=int32), DeviceArray([0, 0, 0, 0, 0], dtype=int32)), (), (), (DeviceArray([[ 0.11138923, -0.20193268],\n",
      "             [ 0.3218486 , -0.6938446 ],\n",
      "             [-0.29520795, -0.5566491 ],\n",
      "             [ 0.03566048,  0.39482087],\n",
      "             [-0.5446372 ,  0.90716356]], dtype=float32), DeviceArray([-1.2630071e-06, -1.3831954e-06], dtype=float32)), (DeviceArray([[ 0.5734267 ],\n",
      "             [-0.61399156]], dtype=float32), DeviceArray([7.5263193e-07], dtype=float32)), ())\n"
     ]
    }
   ],
   "source": [
    "print(serial.name)\n",
    "print(serial.sublayers)\n",
    "print(serial.n_in)\n",
    "print(serial.n_out)\n",
    "print(serial.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = serial(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnp = np.array([1, 2, 3])\n",
    "type(xnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jax.interpreters.xla.DeviceArray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xjax = fastmath.numpy.array([1, 2, 3])\n",
    "type(xjax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
