{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    "## Capturing Text Data\n",
    "\n",
    "### Plain Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODEOWNERS               \u001b[34mdata\u001b[m\u001b[m                     requirements.txt\r\n",
      "README.md                \u001b[34mmine\u001b[m\u001b[m                     sentiment_analysis.ipynb\r\n",
      "\u001b[34mcache\u001b[m\u001b[m                    \u001b[34mnltk_data\u001b[m\u001b[m                text_processing.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = '../../data'\n",
    "NLTK_DATA = '../../nltk_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hieroglyphic writing dates from c. 3000 BC, and is composed of hundreds of symbols. A hieroglyph can represent a word, a sound, or a silent determinative; and the same symbol can serve different purposes in different contexts. Hieroglyphs were a formal script, used on stone monuments and in tombs, that could be as detailed as individual works of art.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in a plain text file\n",
    "with open(os.path.join(DATA, 'hieroglyph.txt'), 'r') as f:\n",
    "    text = f.read()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Livemint</td>\n",
       "      <td>fed's charles plosser sees high bar for change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>us open: stocks fall after fed official hints ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>fed risks falling 'behind the curve', charles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moneynews</td>\n",
       "      <td>fed's plosser: nasty weather has curbed job gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>plosser: fed may have to accelerate tapering pace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      publisher                                              title\n",
       "0      Livemint  fed's charles plosser sees high bar for change...\n",
       "1  IFA Magazine  us open: stocks fall after fed official hints ...\n",
       "2  IFA Magazine  fed risks falling 'behind the curve', charles ...\n",
       "3     Moneynews  fed's plosser: nasty weather has curbed job gr...\n",
       "4        NASDAQ  plosser: fed may have to accelerate tapering pace"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text column from a dataframe\n",
    "df = pd.read_csv(os.path.join(DATA, 'news.csv'))\n",
    "df.head()[['publisher', 'title']]\n",
    "\n",
    "# Convert text column to lowercase\n",
    "df['title'] = df['title'].str.lower()\n",
    "df.head()[['publisher', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": {\n",
      "        \"total\": 1\n",
      "    },\n",
      "    \"contents\": {\n",
      "        \"quotes\": [\n",
      "            {\n",
      "                \"quote\": \"If you get up in the morning and think the future is going to be better, it is a bright day. Otherwise, it's not.\",\n",
      "                \"length\": \"113\",\n",
      "                \"author\": \"Elon Musk\",\n",
      "                \"tags\": [\n",
      "                    \"inspire\",\n",
      "                    \"positive-thinking\"\n",
      "                ],\n",
      "                \"category\": \"inspire\",\n",
      "                \"date\": \"2018-12-05\",\n",
      "                \"permalink\": \"https://theysaidso.com/quote/mbtVO88S_KNdB4gBMyXaUgeF/elon-musk-if-you-get-up-in-the-morning-and-think-the-future-is-going-to-be-bette\",\n",
      "                \"title\": \"Inspiring Quote of the day\",\n",
      "                \"background\": \"https://theysaidso.com/img/bgs/man_on_the_mountain.jpg\",\n",
      "                \"id\": \"mbtVO88S_KNdB4gBMyXaUgeF\"\n",
      "            }\n",
      "        ],\n",
      "        \"copyright\": \"2017-19 theysaidso.com\"\n",
      "    }\n",
      "}\n",
      "If you get up in the morning and think the future is going to be better, it is a bright day. Otherwise, it's not. \n",
      "-- Elon Musk\n"
     ]
    }
   ],
   "source": [
    "# Fetch data from a REST API\n",
    "r = requests.get('https://quotes.rest/qod.json')\n",
    "res = r.json()\n",
    "print(json.dumps(res, indent=4))\n",
    "\n",
    "# Extract relevant object and field\n",
    "q = res['contents']['quotes'][0]\n",
    "print(q['quote'], '\\n--', q['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html op=\"news\"><head><meta name=\"referrer\" content=\"origin\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"><link rel=\"stylesheet\" type=\"text/css\" href=\"news.css?PlzieHqljp3FNCn26L0Q\">\n",
      "            <link rel=\"shortcut icon\" href=\"favicon.ico\">\n",
      "          <link rel=\"alternate\" type=\"application/rss+xml\" title=\"RSS\" href=\"rss\">\n",
      "        <title>Hacker News</title></head><body><center><table id=\"hnmain\" border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"85%\" bgcolor=\"#f6f6ef\">\n",
      "        <tr><td bgcolor=\"#ff6600\"><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\" style=\"padding:2px\"><tr><td style=\"width:18px;padding-right:4px\"><a href=\"https://news.ycombinator.com\"><img src=\"y18.gif\" width=\"18\" height=\"18\" style=\"border:1px white solid;\"></a></td>\n",
      "                  <td style=\"line-height:12pt; height:10px;\"><span class=\"pagetop\"><b class=\"hnname\"><a href=\"news\">Hacker News</a></b>\n",
      "              <a href=\"newest\">new</a> | <a href=\"newcomments\">comments</a> | <a h\n"
     ]
    }
   ],
   "source": [
    "# Fetch a web page\n",
    "r = requests.get('https://news.ycombinator.com')\n",
    "print(r.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            \n",
      "          \n",
      "        Hacker News\n",
      "        \n",
      "                  Hacker News\n",
      "              new | comments | show | ask | jobs | submit            \n",
      "                              login\n",
      "                          \n",
      "              \n",
      "\n",
      "              \n",
      "      1.      Why Do Hospitals Hate Sleep So Much? (motherjones.com)\n",
      "        71 points by curtis 1 hour ago  | hide | 38&nbsp;comments              \n",
      "      \n",
      "                \n",
      "      2.      Announcing Open Source of WPF, Windows Forms, and WinUI (windows.com)\n",
      "        749 points by MikusR 13 hours ago  | hide | 311&nbsp;comments              \n",
      "      \n",
      "                \n",
      "      3.      The Creepy Line: a documentary about Google, Facebook and user manipulation (thecreepyline.com)\n",
      "        30 points by znpy 2 hours ago  | hide | 6&nbsp;comments              \n",
      "      \n",
      "                \n",
      "      4.      Facebook ends platform policy banning apps that copy its features (techcrunch.com)\n",
      "        110 points by brandnewlow 6 hours ago  | hide | 65&nbsp;comments      \n"
     ]
    }
   ],
   "source": [
    "# Remove HTML tags using RegEx\n",
    "pattern = re.compile(r'<.*?>')  # tags look like <...>\n",
    "print(pattern.sub('', r.text)[:1000])  # replace them with blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            \n",
      "          \n",
      "        Hacker News\n",
      "        \n",
      "                  Hacker News\n",
      "              new | comments | show | ask | jobs | submit            \n",
      "                              login\n",
      "                          \n",
      "              \n",
      "\n",
      "              \n",
      "      1.      Why Do Hospitals Hate Sleep So Much? (motherjones.com)\n",
      "        71 points by curtis 1 hour ago  | hide | 38 comments              \n",
      "      \n",
      "                \n",
      "      2.      Announcing Open Source of WPF, Windows Forms, and WinUI (windows.com)\n",
      "        749 points by MikusR 13 hours ago  | hide | 311 comments              \n",
      "      \n",
      "                \n",
      "      3.      The Creepy Line: a documentary about Google, Facebook and user manipulation (thecreepyline.com)\n",
      "        30 points by znpy 2 hours ago  | hide | 6 comments              \n",
      "      \n",
      "                \n",
      "      4.      Facebook ends platform policy banning apps that copy its features (techcrunch.com)\n",
      "        110 points by brandnewlow 6 hours ago  | hide | 65 comments              \n",
      "      \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Remove HTML tags using Beautiful Soup library\n",
    "soup = BeautifulSoup(r.text, 'html5lib')\n",
    "print(soup.get_text()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr class=\"athing\" id=\"18605709\">\n",
       "      <td align=\"right\" class=\"title\" valign=\"top\"><span class=\"rank\">1.</span></td>      <td class=\"votelinks\" valign=\"top\"><center><a href=\"vote?id=18605709&amp;how=up&amp;goto=news\" id=\"up_18605709\"><div class=\"votearrow\" title=\"upvote\"></div></a></center></td><td class=\"title\"><a class=\"storylink\" href=\"https://www.motherjones.com/kevin-drum/2018/12/why-do-hospitals-hate-sleep-so-much/\">Why Do Hospitals Hate Sleep So Much?</a><span class=\"sitebit comhead\"> (<a href=\"from?site=motherjones.com\"><span class=\"sitestr\">motherjones.com</span></a>)</span></td></tr>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all articles\n",
    "summaries = soup.find_all('tr', class_='athing')\n",
    "summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why Do Hospitals Hate Sleep So Much?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract title\n",
    "summaries[0].find('a', class_='storylink').get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Article summaries found. Sample:\n",
      "Why Do Hospitals Hate Sleep So Much?\n"
     ]
    }
   ],
   "source": [
    "# Find all articles, extract titles\n",
    "articles = []\n",
    "summaries = soup.find_all('tr', class_='athing')\n",
    "for summary in summaries:\n",
    "    title = summary.find('a', class_='storylink').get_text().strip()\n",
    "    articles.append((title))\n",
    "\n",
    "print(len(articles), 'Article summaries found. Sample:')\n",
    "print(articles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first time you see The Second Renaissance it may look boring. Look at it at least twice and definitely watch part 2. It will change your view of the matrix. Are the human people the ones who started the war ? Is AI a bad thing ?\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "text = ('The first time you see The Second Renaissance it may look boring. Look at it at least '\n",
    "        'twice and definitely watch part 2. It will change your view of the matrix. Are the '\n",
    "        'human people the ones who started the war ? Is AI a bad thing ?')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first time you see the second renaissance it may look boring. look at it at least twice and definitely watch part 2. it will change your view of the matrix. are the human people the ones who started the war ? is ai a bad thing ?\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase\n",
    "text = text.lower() \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first time you see the second renaissance it may look boring  look at it at least twice and definitely watch part 2  it will change your view of the matrix  are the human people the ones who started the war   is ai a bad thing  \n",
      "the first time you see the second renaissance it may look boring look at it at least twice and definitely watch part 2 it will change your view of the matrix are the human people the ones who started the war is ai a bad thing \n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation characters\n",
    "text = re.sub(r'[^a-zA-Z0-9]', ' ', text) \n",
    "print(text)\n",
    "\n",
    "text = re.sub(r'\\W+', ' ', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'first', 'time', 'you', 'see', 'the', 'second', 'renaissance', 'it', 'may', 'look', 'boring', 'look', 'at', 'it', 'at', 'least', 'twice', 'and', 'definitely', 'watch', 'part', '2', 'it', 'will', 'change', 'your', 'view', 'of', 'the', 'matrix', 'are', 'the', 'human', 'people', 'the', 'ones', 'who', 'started', 'the', 'war', 'is', 'ai', 'a', 'bad', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# Split text into tokens (words)\n",
    "words = text.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK: Natural Language ToolKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.data.path.append(os.path.join(os.getcwd(), 'nltk_data'))\n",
    "nltk.data.path.append(NLTK_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Smith graduated from the University of Washington. He later started an analytics firm called Lux, which catered to enterprise customers.\n"
     ]
    }
   ],
   "source": [
    "# Another sample text\n",
    "text = ('Dr. Smith graduated from the University of Washington. He later started an analytics '\n",
    "        'firm called Lux, which catered to enterprise customers.')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dr.', 'Smith', 'graduated', 'from', 'the', 'University', 'of', 'Washington', '.', 'He', 'later', 'started', 'an', 'analytics', 'firm', 'called', 'Lux', ',', 'which', 'catered', 'to', 'enterprise', 'customers', '.']\n"
     ]
    }
   ],
   "source": [
    "# Split text into words using NLTK\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dr. Smith graduated from the University of Washington.', 'He later started an analytics firm called Lux, which catered to enterprise customers.']\n"
     ]
    }
   ],
   "source": [
    "# Split text into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n"
     ]
    }
   ],
   "source": [
    "# List stop words\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'first', 'time', 'you', 'see', 'the', 'second', 'renaissance', 'it', 'may', 'look', 'boring', 'look', 'at', 'it', 'at', 'least', 'twice', 'and', 'definitely', 'watch', 'part', '2', 'it', 'will', 'change', 'your', 'view', 'of', 'the', 'matrix', 'are', 'the', 'human', 'people', 'the', 'ones', 'who', 'started', 'the', 'war', 'is', 'ai', 'a', 'bad', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# Reset text\n",
    "text = ('The first time you see The Second Renaissance it may look boring. Look at it at least '\n",
    "        'twice and definitely watch part 2. It will change your view of the matrix. Are the '\n",
    "        'human people the ones who started the war ? Is AI a bad thing ?')\n",
    "\n",
    "# Normalize it\n",
    "text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "\n",
    "# Tokenize it\n",
    "words = text.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'time', 'see', 'second', 'renaissance', 'may', 'look', 'boring', 'look', 'least', 'twice', 'definitely', 'watch', 'part', '2', 'change', 'view', 'matrix', 'human', 'people', 'ones', 'started', 'war', 'ai', 'bad', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "words = [w for w in words if w not in stopwords.words('english')]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "# Define a custom grammar\n",
    "my_grammar = nltk.CFG.fromstring('''\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "''')\n",
    "parser = nltk.ChartParser(my_grammar)\n",
    "\n",
    "# Parse a sentence\n",
    "sentence = word_tokenize('I shot an elephant in my pajamas')\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming & Lemmatization\n",
    "\n",
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'time', 'see', 'second', 'renaiss', 'may', 'look', 'bore', 'look', 'least', 'twice', 'definit', 'watch', 'part', '2', 'chang', 'view', 'matrix', 'human', 'peopl', 'one', 'start', 'war', 'ai', 'bad', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# Reduce words to their stems\n",
    "stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'time', 'see', 'second', 'renaissance', 'may', 'look', 'boring', 'look', 'least', 'twice', 'definitely', 'watch', 'part', '2', 'change', 'view', 'matrix', 'human', 'people', 'one', 'started', 'war', 'ai', 'bad', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# Reduce words to their root form\n",
    "lemmed = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "print(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'time', 'see', 'second', 'renaissance', 'may', 'look', 'bore', 'look', 'least', 'twice', 'definitely', 'watch', 'part', '2', 'change', 'view', 'matrix', 'human', 'people', 'one', 'start', 'war', 'ai', 'bad', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize verbs by specifying pos\n",
    "lemmed = [WordNetLemmatizer().lemmatize(w, pos='v') for w in lemmed]\n",
    "print(lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
