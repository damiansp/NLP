{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    AutoConfig, AutoTokenizer, #TrainingArguments, <- not M1 compatible\n",
    "    XLMRobertaConfig)\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    RobertaModel, RobertaPreTrainedModel)\n",
    "\n",
    "from datasets import (\n",
    "    DatasetDict, get_dataset_config_names, load_dataset)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2945fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configs\n"
     ]
    }
   ],
   "source": [
    "xtreme_subsets = get_dataset_config_names('xtreme')\n",
    "print(f'XTREME has {len(xtreme_subsets)} configs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3c4915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith('PAN')]\n",
    "print(len(panx_subsets))\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3700bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xtreme (/Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6810fbd25244f69d33094244627d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# German\n",
    "load_dataset('xtreme', name='PAN-X.de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9163fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xtreme (/Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247aa2b90eda47d79d224c02136386e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-7318edec81f76aa6.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-cbd29dccd93ef58f.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-4433310f7a3b2793.arrow\n",
      "Reusing dataset xtreme (/Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c690467f44e447c0ba0e3bc89fedd4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-4a1996403248b4e2.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-5d4f9e5aefa05972.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-6789784a489dc7d6.arrow\n",
      "Reusing dataset xtreme (/Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4801d4cd204d23affbb0910e555aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-845df155c04c1192.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-4038e5f0ccb7a363.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-e220bc62f3b2de61.arrow\n",
      "Reusing dataset xtreme (/Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36acf96cbcaa464480b7423cf2f78af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-2292d48c0b6f8502.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-56d73ebf7717cb83.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-5117c26f1eb0d215.arrow\n"
     ]
    }
   ],
   "source": [
    "langs = ['de', 'fr', 'it', 'en']\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# Return a DatasetDict if key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict) \n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset('xtreme', name=f'PAN-X.{lang}')\n",
    "    # Shuffle and downsample ea split according to prop. spoken\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "            .shuffle(seed=0)\n",
    "            .select(range(int(frac * ds[split].num_rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3011d609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_training</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               de    fr    it    en\n",
       "n_training  12580  4580  1680  1180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {lang: [panx_ch[lang]['train'].num_rows] for lang in langs},\n",
    "    index=['n_training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf4fb236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch['de']['train'][0]\n",
    "for k, v in element.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb48990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for k, v in panx_ch['de']['train'].features.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ac65ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = panx_ch['de']['train'].features['ner_tags'].feature\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "982503da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {'ner_tags_str': [tags.int2str(idx) \n",
    "                             for idx in batch['ner_tags']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38cd93ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-b62b878f6a8a1f1b.arrow\n",
      "Loading cached processed dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-58ddfb338a44ff7d.arrow\n",
      "Loading cached processed dataset at /Users/damiansp/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-b059df060587602c.arrow\n"
     ]
    }
   ],
   "source": [
    "panx_de = panx_ch['de'].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8682d08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>Sie</td>\n",
       "      <td>geht</td>\n",
       "      <td>hinter</td>\n",
       "      <td>Walluf</td>\n",
       "      <td>nahtlos</td>\n",
       "      <td>in</td>\n",
       "      <td>die</td>\n",
       "      <td>Bundesautobahn</td>\n",
       "      <td>66</td>\n",
       "      <td>über</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1       2       3        4   5    6               7      8   \\\n",
       "tokens  Sie  geht  hinter  Walluf  nahtlos  in  die  Bundesautobahn     66   \n",
       "tags      O     O       O   B-ORG        O   O    O           B-ORG  I-ORG   \n",
       "\n",
       "          9  10  \n",
       "tokens  über  .  \n",
       "tags       O  O  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_ex = panx_de['train'][1]\n",
    "pd.DataFrame([de_ex['tokens'], de_ex['ner_tags_str']], \n",
    "             index=['tokens', 'tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c8a1e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>2683</td>\n",
       "      <td>3172</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2573</td>\n",
       "      <td>3180</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>5366</td>\n",
       "      <td>6186</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ORG   LOC   PER\n",
       "validation  2683  3172  2893\n",
       "test        2573  3180  3071\n",
       "train       5366  6186  5810"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset['ner_tags_str']:\n",
    "        for tag in row:\n",
    "            if tag.startswith('B'):\n",
    "                tag_type = tag.split('-')[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7589fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_mod_name = 'bert-base-cased'\n",
    "xlmr_mod_name = 'xlm-roberta-base'\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_mod_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_mod_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb54f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Jack Sparrow loves New York!'\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec4e5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokens = xlmr_tokenizer(text).tokens()\n",
    "xlmr_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6f07ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'\\u2581'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3063d49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Jack Sparrow loves New York!</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(xlmr_tokens).replace(u'\\u2581', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfff790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(\n",
    "            config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(\n",
    "            self, input_ids=None, attention_mask=None,\n",
    "            token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs)\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e838e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2idx = {tag: idx for idx, tag in idx2tag.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b94c5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmr_config = AutoConfig.from_pretrained(\n",
    "    xlmr_mod_name,\n",
    "    num_labels=tags.num_classes,\n",
    "    id2label=idx2tag,\n",
    "    label2id=tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb84f413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "xlmr_model = (XLMRobertaForTokenClassification\n",
    "              .from_pretrained(xlmr_mod_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50ea373c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors='pt')\n",
    "pd.DataFrame(\n",
    "    [xlmr_tokens, input_ids[0].numpy()], index=['Tokens', 'Input IDs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1628ba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. tokens in seq: 10\n",
      "Shape out: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "print(f'N. tokens in seq: {len(xlmr_tokens)}')\n",
    "print(f'Shape out: {outputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e6227cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    input_ids = (\n",
    "        xlmr_tokenizer(text, return_tensors='pt').input_ids.to(device))\n",
    "    outputs = model(inputs)[0]\n",
    "    preds = torch.argmax(outputs, dim=2)\n",
    "    preds = [tag.names[p] for p in preds[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dad5277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = de_ex['tokens'], de_ex['ner_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c84a6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Sie</td>\n",
       "      <td>▁geht</td>\n",
       "      <td>▁hinter</td>\n",
       "      <td>▁Wall</td>\n",
       "      <td>uf</td>\n",
       "      <td>▁na</td>\n",
       "      <td>ht</td>\n",
       "      <td>los</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁die</td>\n",
       "      <td>▁Bundes</td>\n",
       "      <td>auto</td>\n",
       "      <td>bahn</td>\n",
       "      <td>▁66</td>\n",
       "      <td>▁über</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1      2        3      4   5    6   7    8    9     10  \\\n",
       "Tokens  <s>  ▁Sie  ▁geht  ▁hinter  ▁Wall  uf  ▁na  ht  los  ▁in  ▁die   \n",
       "\n",
       "             11    12    13   14     15 16 17    18  \n",
       "Tokens  ▁Bundes  auto  bahn  ▁66  ▁über  ▁  .  </s>  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(\n",
    "    de_ex['tokens'], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(\n",
    "    tokenized_input['input_ids'])\n",
    "pd.DataFrame([tokens], index=['Tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc3391d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Sie</td>\n",
       "      <td>▁geht</td>\n",
       "      <td>▁hinter</td>\n",
       "      <td>▁Wall</td>\n",
       "      <td>uf</td>\n",
       "      <td>▁na</td>\n",
       "      <td>ht</td>\n",
       "      <td>los</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁die</td>\n",
       "      <td>▁Bundes</td>\n",
       "      <td>auto</td>\n",
       "      <td>bahn</td>\n",
       "      <td>▁66</td>\n",
       "      <td>▁über</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1      2        3      4   5    6   7    8    9     10  \\\n",
       "Tokens     <s>  ▁Sie  ▁geht  ▁hinter  ▁Wall  uf  ▁na  ht  los  ▁in  ▁die   \n",
       "Word IDs  None     0      1        2      3   3    4   4    4    5     6   \n",
       "\n",
       "               11    12    13   14     15  16  17    18  \n",
       "Tokens    ▁Bundes  auto  bahn  ▁66  ▁über   ▁   .  </s>  \n",
       "Word IDs        7     7     7    8      9  10  10  None  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=['Tokens', 'Word IDs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1291409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>word ids</th>\n",
       "      <th>label ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Sie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁geht</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁hinter</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁Wall</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uf</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁na</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ht</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>los</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>▁in</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>▁die</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>▁Bundes</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>auto</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bahn</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>▁66</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>▁über</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>▁</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tokens word ids label ids labels\n",
       "0       <s>     None         0      O\n",
       "1      ▁Sie        0         0      O\n",
       "2     ▁geht        1         0      O\n",
       "3   ▁hinter        2         3  B-ORG\n",
       "4     ▁Wall        3         0      O\n",
       "5        uf        3         0      O\n",
       "6       ▁na        4         0      O\n",
       "7        ht        4         3  B-ORG\n",
       "8       los        4         4  I-ORG\n",
       "9       ▁in        5         0      O\n",
       "10     ▁die        6         0      O\n",
       "11  ▁Bundes        7      None   None\n",
       "12     auto        7      None   None\n",
       "13     bahn        7      None   None\n",
       "14      ▁66        8      None   None\n",
       "15    ▁über        9      None   None\n",
       "16        ▁       10      None   None\n",
       "17        .       10      None   None\n",
       "18     </s>     None      None   None"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == prev_word_idx:\n",
    "        labels.append(-100)\n",
    "    else:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    prev_word_idx = word_idx\n",
    "    \n",
    "labels = [idx2tag[lab] if lab != -100 else 'IGN' for lab in label_ids]\n",
    "index = ['tokens', 'word ids', 'label ids', 'labels']\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cfff64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(\n",
    "        examples['tokens'], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, lab in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        prev_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == prev_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(lab[word_idx])\n",
    "            prev_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a08481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=['langs', 'ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77d149b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758b7e55428c4ff389ccd7ff06bd4387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15e204cc44441b0a07d33d70c8cdbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ed238aac1b425b8d061a0ee9724f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ch['de'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1a4db",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ea326c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = [\n",
    "    ['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'],\n",
    "    ['B-PER', 'I-PER', 'O']]\n",
    "y_pred = [\n",
    "    ['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'],\n",
    "    ['B-PER', 'I-PER', 'O']]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e94ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_preds(preds, label_ids):\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "    for batch in range(batch_size):\n",
    "        ex_labels, ex_preds = [], []\n",
    "        for seq in rang(seq_len):\n",
    "            if lable_ids[batch, seq] != 100:\n",
    "                ex_labels.append(idx2tag[label_ids[batch][seq]])\n",
    "                ex_preds.append(idx2tag[preds[batch][seq]])\n",
    "        labels_list.append(ex_labels)\n",
    "        preds_list.append(ex_preds)\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef40e59",
   "metadata": {},
   "source": [
    "```python\n",
    "EPOCHS = 3\n",
    "BATCH = 24\n",
    "LOG_STEPS = len(panx_de_encoded['train']) // BATCH\n",
    "mod_name = f'{xlmr_model_name}-finetuned-panx-de'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=mod_name,\n",
    "    log_level='error',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH,\n",
    "    per_device_eval_batch_size=BATCH,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_steps=1e6,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=LOG_STEPS,\n",
    "    push_to_hub=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ede1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
